{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca9789",
   "metadata": {},
   "source": [
    "## Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2139fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/03 23:54:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/03 23:54:05 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/03 23:54:05 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia '\n",
       " 'Artificial/YOLOv8_living-room_furniture/mlruns'), creation_time=1770106818785, experiment_id='1', last_update_time=1770106818785, lifecycle_stage='active', name='Furniture_Detection_System', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# 1. CONFIGURACIÓN DE RUTAS Y ENTORNO\n",
    "# Definir la raíz del proyecto\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "# Rutas de datos\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"base_dataset\", \"Living-Room-9\")\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed_dataset\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "MODELS_HISTORY = os.path.join(BASE_DIR, \"models_history\")\n",
    "\n",
    "# Configuración de MLflow\n",
    "MLFLOW_DB_PATH = os.path.join(BASE_DIR, \"mlflow.db\")\n",
    "MLFLOW_ARTIFACTS_PATH = os.path.join(BASE_DIR, \"mlruns\")\n",
    "\n",
    "REGISTERED_MODEL_NAME = \"Furniture_Model_YOLO\"\n",
    "\n",
    "# Verificación de seguridad\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "    print(f\"\\nALERTA: No se encontró la carpeta RAW en:\\n{RAW_DATA_DIR}\")\n",
    "\n",
    "# MAPA DE TRADUCCIÓN\n",
    "ID_MAPPING = {\n",
    "    12: 0, # Sofa\n",
    "    11: 1, # Rug\n",
    "    19: 2  # Pillows\n",
    "}\n",
    "CLASSES_NAMES = {0: 'Sofa', 1: 'Rug', 2: 'Pillows'}\n",
    "\n",
    "# Crear directorios necesarios\n",
    "for d in [PROCESSED_DATA_DIR, MODELS_DIR, MODELS_HISTORY, MLFLOW_ARTIFACTS_PATH]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Config MlFlow\n",
    "# 1. Conectar a la base de datos\n",
    "db_uri = f\"sqlite:///{MLFLOW_DB_PATH.replace(os.sep, '/')}\"\n",
    "mlflow.set_tracking_uri(db_uri)\n",
    "\n",
    "# 2. Configurar Experimento\n",
    "experiment_name = \"Furniture_Detection_System\"\n",
    "try:\n",
    "    mlflow.create_experiment(\n",
    "        name=experiment_name,\n",
    "        artifact_location=f\"file:///{MLFLOW_ARTIFACTS_PATH.replace(os.sep, '/')}\"\n",
    "    )\n",
    "except:\n",
    "    pass \n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e0d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Limpiando y reconstruyendo dataset\n",
      "train: 3530 imágenes procesadas.\n",
      "valid: 149 imágenes procesadas.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_dataset():\n",
    "    \"\"\"\n",
    "    Procesa un split (train/valid):\n",
    "    1. Lee etiquetas originales.\n",
    "    2. Filtra solo las clases 11, 12, 19.\n",
    "    3. Remapea a 0, 1, 2.\n",
    "    4. Si la imagen tiene al menos un objeto válido, la copia al nuevo destino.\n",
    "    \"\"\"\n",
    "    print(f\" Limpiando y reconstruyendo dataset\")\n",
    "    \n",
    "    # Borrar versión anterior para asegurar limpieza total\n",
    "    if os.path.exists(PROCESSED_DATA_DIR):\n",
    "        shutil.rmtree(PROCESSED_DATA_DIR)\n",
    "\n",
    "    for split in [\"train\", \"valid\"]:\n",
    "        src_imgs_dir = os.path.join(RAW_DATA_DIR, split, \"images\")\n",
    "        if not os.path.exists(src_imgs_dir): continue\n",
    "\n",
    "        # Crear carpetas destino\n",
    "        os.makedirs(os.path.join(PROCESSED_DATA_DIR, split, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(PROCESSED_DATA_DIR, split, \"labels\"), exist_ok=True)\n",
    "        \n",
    "        # Buscar imágenes\n",
    "        src_imgs = glob.glob(os.path.join(src_imgs_dir, \"*\"))\n",
    "        count = 0\n",
    "        \n",
    "        for img_path in src_imgs:\n",
    "            # Nombre del archivo sin extensión\n",
    "            basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            label_src = os.path.join(RAW_DATA_DIR, split, \"labels\", basename + \".txt\")\n",
    "            \n",
    "            if os.path.exists(label_src):\n",
    "                with open(label_src, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                new_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.split()\n",
    "                    # Si el ID está en nuestro mapa (12, 11, 19), lo traducimos y guardamos\n",
    "                    if parts and int(parts[0]) in ID_MAPPING:\n",
    "                        new_id = ID_MAPPING[int(parts[0])]\n",
    "                        new_lines.append(f\"{new_id} {' '.join(parts[1:])}\\n\")\n",
    "                \n",
    "                # Solo guardamos si la imagen tiene al menos un mueble de interés\n",
    "                if new_lines:\n",
    "                    shutil.copy(img_path, os.path.join(PROCESSED_DATA_DIR, split, \"images\"))\n",
    "                    with open(os.path.join(PROCESSED_DATA_DIR, split, \"labels\", basename + \".txt\"), 'w') as f:\n",
    "                        f.writelines(new_lines)\n",
    "                    count += 1\n",
    "        print(f\"{split}: {count} imágenes procesadas.\")\n",
    "\n",
    "sanitize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328bef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo YAML para el entrenamiento\n",
    "yaml_path = os.path.join(PROCESSED_DATA_DIR, \"data_clean.yaml\")\n",
    "yaml_content = {\n",
    "    'path': PROCESSED_DATA_DIR.replace('\\\\', '/'),\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'nc': 3,\n",
    "    'names': CLASSES_NAMES\n",
    "}\n",
    "\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984bc4",
   "metadata": {},
   "source": [
    "## Base Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a52d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recortando dataset: De 3530 a solo 50 imágenes.\n",
      "New https://pypi.org/project/ultralytics/8.4.10 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\sabotage.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=5, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=base_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 9.45.1 MB/s, size: 111.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\train\\labels... 50 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 50/50 422.6it/s 0.1s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 210.580.9 MB/s, size: 56.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\processed_dataset\\valid\\labels.cache... 149 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 149/149  0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/03 03:21:13 INFO mlflow.tracking.fluent: Experiment with name 'c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(eb960f60c81448d199cb8ea6b0b2de2e) to sqlite:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia Artificial/YOLOv8_living-room_furniture/mlflow.db\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5      1.12G      1.334      3.297      1.536          9        640: 100% ━━━━━━━━━━━━ 7/7 1.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 5.1it/s 2.0s.2s\n",
      "                   all        149        735    0.00741       0.64      0.226      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5      1.29G      1.233      3.115      1.384         12        640: 100% ━━━━━━━━━━━━ 7/7 6.5it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 6.0it/s 1.7s.2s\n",
      "                   all        149        735    0.00807      0.641      0.358      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5       1.3G      1.181      2.887      1.329         15        640: 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 6.7it/s 1.5s.2s\n",
      "                   all        149        735    0.00878      0.668      0.407      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5      1.31G      1.111      2.499      1.256         16        640: 100% ━━━━━━━━━━━━ 7/7 6.9it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 7.4it/s 1.4s.2s\n",
      "                   all        149        735    0.00893      0.683      0.426      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5      1.32G      1.121      2.217      1.313         12        640: 100% ━━━━━━━━━━━━ 7/7 7.4it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 7.2it/s 1.4s.2s\n",
      "                   all        149        735    0.00831      0.661      0.441      0.302\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 73 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 8.9it/s 1.1s.1s\n",
      "                   all        149        735    0.00844      0.667      0.442      0.302\n",
      "                  Sofa        135        164     0.0159          1      0.825      0.637\n",
      "                   Rug        141        142     0.0089      0.979      0.499       0.27\n",
      "               Pillows        104        429   0.000545     0.0233    0.00124   0.000617\n",
      "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to sqlite:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia Artificial/YOLOv8_living-room_furniture/mlflow.db\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "\n",
      "mAP50 del Modelo base: 0.4416\n",
      "Modelo guardado en: c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models\\best.pt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def train_starved_base_model():\n",
    "    \n",
    "    # NOMBRE UNIFICADO PARA EVITAR ERRORES\n",
    "    EXPERIMENT_FOLDER = \"base_model\"\n",
    "    \n",
    "    # 1. Crear un dataset temporal (Solo 50 fotos)\n",
    "    sabotage_dir = os.path.join(BASE_DIR, \"data\", \"sabotage_dataset\")\n",
    "    sabotage_yaml = os.path.join(sabotage_dir, \"sabotage.yaml\")\n",
    "    \n",
    "    # Limpieza previa\n",
    "    if os.path.exists(sabotage_dir): shutil.rmtree(sabotage_dir)\n",
    "    \n",
    "    os.makedirs(os.path.join(sabotage_dir, \"train\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(sabotage_dir, \"train\", \"labels\"), exist_ok=True)\n",
    "\n",
    "    # 2. Seleccionar SOLO 50 imágenes al azar\n",
    "    all_train_imgs = glob.glob(os.path.join(PROCESSED_DATA_DIR, \"train\", \"images\", \"*.jpg\"))\n",
    "    \n",
    "    # Validación por si no hay imágenes\n",
    "    if not all_train_imgs:\n",
    "        print(\"Error: No hay imágenes en processed_dataset/train\")\n",
    "        return\n",
    "\n",
    "    selected_imgs = random.sample(all_train_imgs, min(50, len(all_train_imgs)))\n",
    "    \n",
    "    print(f\" Recortando dataset: De {len(all_train_imgs)} a solo {len(selected_imgs)} imágenes.\")\n",
    "    \n",
    "    for img_path in selected_imgs:\n",
    "        basename = os.path.basename(img_path)\n",
    "        lbl_path = os.path.join(PROCESSED_DATA_DIR, \"train\", \"labels\", basename.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(lbl_path):\n",
    "            shutil.copy(img_path, os.path.join(sabotage_dir, \"train\", \"images\", basename))\n",
    "            shutil.copy(lbl_path, os.path.join(sabotage_dir, \"train\", \"labels\", basename.replace('.jpg', '.txt')))\n",
    "\n",
    "    # 3. Crear YAML de sabotaje\n",
    "    original_valid_dir = os.path.join(PROCESSED_DATA_DIR, \"valid\", \"images\")\n",
    "    \n",
    "    data_config = {\n",
    "        'path': '', \n",
    "        'train': os.path.join(sabotage_dir, \"train\", \"images\"),\n",
    "        'val': original_valid_dir, \n",
    "        'nc': 3,\n",
    "        'names': CLASSES_NAMES\n",
    "    }\n",
    "    \n",
    "    with open(sabotage_yaml, 'w') as f:\n",
    "        yaml.dump(data_config, f)\n",
    "\n",
    "    # 4. Entrenar\n",
    "    model = YOLO(\"yolov8n.pt\") \n",
    "    \n",
    "    if mlflow.active_run(): mlflow.end_run()\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Base_Model\") as run:\n",
    "        \n",
    "        results = model.train(\n",
    "            data=sabotage_yaml,\n",
    "            epochs=5,           \n",
    "            imgsz=640,          \n",
    "            batch=8,\n",
    "            project=MODELS_HISTORY,\n",
    "            name=EXPERIMENT_FOLDER, \n",
    "            exist_ok=True,\n",
    "            plots=False\n",
    "        )\n",
    "        \n",
    "        metrics = results.box\n",
    "        print(f\"\\nmAP50 del Modelo base: {metrics.map50:.4f}\")\n",
    "\n",
    "        # Guardar como best.pt oficial}\n",
    "        src_weights = os.path.join(MODELS_HISTORY, EXPERIMENT_FOLDER, \"weights\", \"best.pt\")\n",
    "        dst_weights = os.path.join(MODELS_DIR, \"best.pt\")\n",
    "        \n",
    "        if os.path.exists(src_weights):\n",
    "            shutil.copy(src_weights, dst_weights)\n",
    "            print(f\"Modelo guardado en: {dst_weights}\")\n",
    "            \n",
    "            # Registrar\n",
    "            mlflow.log_metric(\"map50\", metrics.map50)\n",
    "            mlflow.log_metric(\"map50-95\", metrics.map)\n",
    "            mlflow.log_artifact(dst_weights, artifact_path=\"weights\")\n",
    "            \n",
    "            client = MlflowClient()\n",
    "            try: client.create_registered_model(REGISTERED_MODEL_NAME)\n",
    "            except: pass\n",
    "            \n",
    "            client.create_model_version(\n",
    "                name=REGISTERED_MODEL_NAME,\n",
    "                source=f\"runs:/{run.info.run_id}/weights\",\n",
    "                run_id=run.info.run_id\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Error: No se encontró el archivo en {src_weights}\")\n",
    "\n",
    "train_starved_base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee563c78",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85bbba6",
   "metadata": {},
   "source": [
    "We successfully reduced the dataset classes to the 3 classes of our interest, eliminating images that did not contain any of the 3 mentioned classes. Additionally, due to the high performance of the YOLO model, we sabotaged its training, making it use only 50 images and train for only 5 epochs. Thanks to this, we managed to generate a baseline with a mAP50 of 44%, allowing future experiments to observe improvement and learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
