{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425d0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca9789",
   "metadata": {},
   "source": [
    "## Configuración del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2139fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/03 03:20:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/03 03:20:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/02/03 03:20:17 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/03 03:20:18 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia '\n",
       " 'Artificial/YOLOv8_living-room_furniture/mlruns'), creation_time=1770106818785, experiment_id='1', last_update_time=1770106818785, lifecycle_stage='active', name='Furniture_Detection_System', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# 1. CONFIGURACIÓN DE RUTAS Y ENTORNO\n",
    "# Definir la raíz del proyecto\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "# Rutas de datos\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"base_dataset\", \"Living-Room-9\")\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed_dataset\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "MODELS_HISTORY = os.path.join(BASE_DIR, \"models_history\")\n",
    "\n",
    "# Configuración de MLflow\n",
    "MLFLOW_DB_PATH = os.path.join(BASE_DIR, \"mlflow.db\")\n",
    "MLFLOW_ARTIFACTS_PATH = os.path.join(BASE_DIR, \"mlruns\")\n",
    "\n",
    "REGISTERED_MODEL_NAME = \"Furniture_Model_YOLO\"\n",
    "\n",
    "# Verificación de seguridad\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "    print(f\"\\nALERTA: No se encontró la carpeta RAW en:\\n{RAW_DATA_DIR}\")\n",
    "\n",
    "# MAPA DE TRADUCCIÓN\n",
    "ID_MAPPING = {\n",
    "    12: 0, # Sofa\n",
    "    11: 1, # Rug\n",
    "    19: 2  # Pillows\n",
    "}\n",
    "CLASSES_NAMES = {0: 'Sofa', 1: 'Rug', 2: 'Pillows'}\n",
    "\n",
    "# Crear directorios necesarios\n",
    "for d in [PROCESSED_DATA_DIR, MODELS_DIR, MODELS_HISTORY, MLFLOW_ARTIFACTS_PATH]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Config MlFlow\n",
    "# 1. Conectar a la base de datos\n",
    "db_uri = f\"sqlite:///{MLFLOW_DB_PATH.replace(os.sep, '/')}\"\n",
    "mlflow.set_tracking_uri(db_uri)\n",
    "\n",
    "# 2. Configurar Experimento\n",
    "experiment_name = \"Furniture_Detection_System\"\n",
    "try:\n",
    "    mlflow.create_experiment(\n",
    "        name=experiment_name,\n",
    "        artifact_location=f\"file:///{MLFLOW_ARTIFACTS_PATH.replace(os.sep, '/')}\"\n",
    "    )\n",
    "except:\n",
    "    pass \n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e0d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Limpiando y reconstruyendo dataset\n",
      "train: 3530 imágenes procesadas.\n",
      "valid: 149 imágenes procesadas.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_dataset():\n",
    "    \"\"\"\n",
    "    Procesa un split (train/valid):\n",
    "    1. Lee etiquetas originales.\n",
    "    2. Filtra solo las clases 11, 12, 19.\n",
    "    3. Remapea a 0, 1, 2.\n",
    "    4. Si la imagen tiene al menos un objeto válido, la copia al nuevo destino.\n",
    "    \"\"\"\n",
    "    print(f\" Limpiando y reconstruyendo dataset\")\n",
    "    \n",
    "    # Borrar versión anterior para asegurar limpieza total\n",
    "    if os.path.exists(PROCESSED_DATA_DIR):\n",
    "        shutil.rmtree(PROCESSED_DATA_DIR)\n",
    "\n",
    "    for split in [\"train\", \"valid\"]:\n",
    "        src_imgs_dir = os.path.join(RAW_DATA_DIR, split, \"images\")\n",
    "        if not os.path.exists(src_imgs_dir): continue\n",
    "\n",
    "        # Crear carpetas destino\n",
    "        os.makedirs(os.path.join(PROCESSED_DATA_DIR, split, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(PROCESSED_DATA_DIR, split, \"labels\"), exist_ok=True)\n",
    "        \n",
    "        # Buscar imágenes\n",
    "        src_imgs = glob.glob(os.path.join(src_imgs_dir, \"*\"))\n",
    "        count = 0\n",
    "        \n",
    "        for img_path in src_imgs:\n",
    "            # Nombre del archivo sin extensión\n",
    "            basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            label_src = os.path.join(RAW_DATA_DIR, split, \"labels\", basename + \".txt\")\n",
    "            \n",
    "            if os.path.exists(label_src):\n",
    "                with open(label_src, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                new_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.split()\n",
    "                    # Si el ID está en nuestro mapa (12, 11, 19), lo traducimos y guardamos\n",
    "                    if parts and int(parts[0]) in ID_MAPPING:\n",
    "                        new_id = ID_MAPPING[int(parts[0])]\n",
    "                        new_lines.append(f\"{new_id} {' '.join(parts[1:])}\\n\")\n",
    "                \n",
    "                # Solo guardamos si la imagen tiene al menos un mueble de interés\n",
    "                if new_lines:\n",
    "                    shutil.copy(img_path, os.path.join(PROCESSED_DATA_DIR, split, \"images\"))\n",
    "                    with open(os.path.join(PROCESSED_DATA_DIR, split, \"labels\", basename + \".txt\"), 'w') as f:\n",
    "                        f.writelines(new_lines)\n",
    "                    count += 1\n",
    "        print(f\"{split}: {count} imágenes procesadas.\")\n",
    "\n",
    "sanitize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328bef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo YAML para el entrenamiento\n",
    "yaml_path = os.path.join(PROCESSED_DATA_DIR, \"data_clean.yaml\")\n",
    "yaml_content = {\n",
    "    'path': PROCESSED_DATA_DIR.replace('\\\\', '/'),\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'nc': 3,\n",
    "    'names': CLASSES_NAMES\n",
    "}\n",
    "\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984bc4",
   "metadata": {},
   "source": [
    "## Entrenamiento base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a52d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recortando dataset: De 3530 a solo 50 imágenes.\n",
      "New https://pypi.org/project/ultralytics/8.4.10 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\sabotage.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=5, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=base_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 9.45.1 MB/s, size: 111.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\train\\labels... 50 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 50/50 422.6it/s 0.1s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\sabotage_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 210.580.9 MB/s, size: 56.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\data\\processed_dataset\\valid\\labels.cache... 149 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 149/149  0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/03 03:21:13 INFO mlflow.tracking.fluent: Experiment with name 'c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(eb960f60c81448d199cb8ea6b0b2de2e) to sqlite:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia Artificial/YOLOv8_living-room_furniture/mlflow.db\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5      1.12G      1.334      3.297      1.536          9        640: 100% ━━━━━━━━━━━━ 7/7 1.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 5.1it/s 2.0s.2s\n",
      "                   all        149        735    0.00741       0.64      0.226      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5      1.29G      1.233      3.115      1.384         12        640: 100% ━━━━━━━━━━━━ 7/7 6.5it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 6.0it/s 1.7s.2s\n",
      "                   all        149        735    0.00807      0.641      0.358      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5       1.3G      1.181      2.887      1.329         15        640: 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 6.7it/s 1.5s.2s\n",
      "                   all        149        735    0.00878      0.668      0.407      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5      1.31G      1.111      2.499      1.256         16        640: 100% ━━━━━━━━━━━━ 7/7 6.9it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 7.4it/s 1.4s.2s\n",
      "                   all        149        735    0.00893      0.683      0.426      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5      1.32G      1.121      2.217      1.313         12        640: 100% ━━━━━━━━━━━━ 7/7 7.4it/s 1.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 7.2it/s 1.4s.2s\n",
      "                   all        149        735    0.00831      0.661      0.441      0.302\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models_history\\base_model\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 73 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 8.9it/s 1.1s.1s\n",
      "                   all        149        735    0.00844      0.667      0.442      0.302\n",
      "                  Sofa        135        164     0.0159          1      0.825      0.637\n",
      "                   Rug        141        142     0.0089      0.979      0.499       0.27\n",
      "               Pillows        104        429   0.000545     0.0233    0.00124   0.000617\n",
      "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to sqlite:///c:/Users/andre/OneDrive/Documents/UPS/Inteligencia Artificial/YOLOv8_living-room_furniture/mlflow.db\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "\n",
      "mAP50 del Modelo base: 0.4416\n",
      "Modelo guardado en: c:\\Users\\andre\\OneDrive\\Documents\\UPS\\Inteligencia Artificial\\YOLOv8_living-room_furniture\\models\\best.pt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import yaml\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def train_starved_base_model():\n",
    "    \n",
    "    # NOMBRE UNIFICADO PARA EVITAR ERRORES\n",
    "    EXPERIMENT_FOLDER = \"base_model\"\n",
    "    \n",
    "    # 1. Crear un dataset temporal (Solo 50 fotos)\n",
    "    sabotage_dir = os.path.join(BASE_DIR, \"data\", \"sabotage_dataset\")\n",
    "    sabotage_yaml = os.path.join(sabotage_dir, \"sabotage.yaml\")\n",
    "    \n",
    "    # Limpieza previa\n",
    "    if os.path.exists(sabotage_dir): shutil.rmtree(sabotage_dir)\n",
    "    \n",
    "    os.makedirs(os.path.join(sabotage_dir, \"train\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(sabotage_dir, \"train\", \"labels\"), exist_ok=True)\n",
    "\n",
    "    # 2. Seleccionar SOLO 50 imágenes al azar\n",
    "    all_train_imgs = glob.glob(os.path.join(PROCESSED_DATA_DIR, \"train\", \"images\", \"*.jpg\"))\n",
    "    \n",
    "    # Validación por si no hay imágenes\n",
    "    if not all_train_imgs:\n",
    "        print(\"Error: No hay imágenes en processed_dataset/train\")\n",
    "        return\n",
    "\n",
    "    selected_imgs = random.sample(all_train_imgs, min(50, len(all_train_imgs)))\n",
    "    \n",
    "    print(f\" Recortando dataset: De {len(all_train_imgs)} a solo {len(selected_imgs)} imágenes.\")\n",
    "    \n",
    "    for img_path in selected_imgs:\n",
    "        basename = os.path.basename(img_path)\n",
    "        lbl_path = os.path.join(PROCESSED_DATA_DIR, \"train\", \"labels\", basename.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(lbl_path):\n",
    "            shutil.copy(img_path, os.path.join(sabotage_dir, \"train\", \"images\", basename))\n",
    "            shutil.copy(lbl_path, os.path.join(sabotage_dir, \"train\", \"labels\", basename.replace('.jpg', '.txt')))\n",
    "\n",
    "    # 3. Crear YAML de sabotaje\n",
    "    original_valid_dir = os.path.join(PROCESSED_DATA_DIR, \"valid\", \"images\")\n",
    "    \n",
    "    data_config = {\n",
    "        'path': '', \n",
    "        'train': os.path.join(sabotage_dir, \"train\", \"images\"),\n",
    "        'val': original_valid_dir, \n",
    "        'nc': 3,\n",
    "        'names': CLASSES_NAMES\n",
    "    }\n",
    "    \n",
    "    with open(sabotage_yaml, 'w') as f:\n",
    "        yaml.dump(data_config, f)\n",
    "\n",
    "    # 4. Entrenar\n",
    "    model = YOLO(\"yolov8n.pt\") \n",
    "    \n",
    "    if mlflow.active_run(): mlflow.end_run()\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Base_Model\") as run:\n",
    "        \n",
    "        results = model.train(\n",
    "            data=sabotage_yaml,\n",
    "            epochs=5,           \n",
    "            imgsz=640,          \n",
    "            batch=8,\n",
    "            project=MODELS_HISTORY,\n",
    "            name=EXPERIMENT_FOLDER, \n",
    "            exist_ok=True,\n",
    "            plots=False\n",
    "        )\n",
    "        \n",
    "        metrics = results.box\n",
    "        print(f\"\\nmAP50 del Modelo base: {metrics.map50:.4f}\")\n",
    "\n",
    "        # Guardar como best.pt oficial}\n",
    "        src_weights = os.path.join(MODELS_HISTORY, EXPERIMENT_FOLDER, \"weights\", \"best.pt\")\n",
    "        dst_weights = os.path.join(MODELS_DIR, \"best.pt\")\n",
    "        \n",
    "        if os.path.exists(src_weights):\n",
    "            shutil.copy(src_weights, dst_weights)\n",
    "            print(f\"Modelo guardado en: {dst_weights}\")\n",
    "            \n",
    "            # Registrar\n",
    "            mlflow.log_metric(\"map50\", metrics.map50)\n",
    "            mlflow.log_metric(\"map50-95\", metrics.map)\n",
    "            mlflow.log_artifact(dst_weights, artifact_path=\"weights\")\n",
    "            \n",
    "            client = MlflowClient()\n",
    "            try: client.create_registered_model(REGISTERED_MODEL_NAME)\n",
    "            except: pass\n",
    "            \n",
    "            client.create_model_version(\n",
    "                name=REGISTERED_MODEL_NAME,\n",
    "                source=f\"runs:/{run.info.run_id}/weights\",\n",
    "                run_id=run.info.run_id\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Error: No se encontró el archivo en {src_weights}\")\n",
    "\n",
    "train_starved_base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee563c78",
   "metadata": {},
   "source": [
    "## Conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85bbba6",
   "metadata": {},
   "source": [
    "Se logró reducir las clases del dataset a las 3 clases de nuestro interés, eliminando imágenes que pudieran no contener ninguna de las 3 clases mencionadas. Además, debido al alto rendimiento del modelo YOLO, se saboteó su entrenamiento, haciendo que use solo 50 imágenes y que entrene durante solo 5 epochs, gracias a esto se logro generar una base media con un mAP50 del 44%, permitiendo que en los futuros experimentos se pueda observar una mejora y aprendizaje."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
